usewandb: true
random_seed: love ytq forever.
device: null

action:
  type: train
  args:
    n_epoch: 1000000
    ckpt_save_name: checkpoints/transformer/v2-{epoch:05d}.ckpt
    per_epoch_save: 10
    betas: [0.9, 0.98]
    eps: 1e-9
    scheduler_factor: 0.05
    scheduler_warmup: 30
    # n_validation_sample: 12 # Change this by change `evaluate_dataset.cut_off`
    latent_code_loss_ratio: 0.8

evaluator:
  gensdf_model_path: null
  eval_mesh_output_path: logs/transformer_eval_mesh_output_path
  resolution: 256
  max_batch: 262144 # 2 ^ 18

# Dataset & Dataloader config
dataset:
  type: file
  args:
    dataset_path: dataset/4_transformer_dataset
    description_for_each_file: 6
    cut_off: -1

evaluate_dataset:
  type: file
  args:
    dataset_path: dataset/4_transformer_dataset
    description_for_each_file: 6
    cut_off: 256

dataloader:
  args:
    batch_size: 512
    num_workers: 10
    shuffle: true

evaluate_dataloader:
  args:
    batch_size: 256
    num_workers: 10
    shuffle: false

part_structure:
  bounding_box: 6
  joint_data_origin: 3
  joint_data_direction: 3
  limit: 4
  latent_code: 768

# Global Model Parameters
model_parameter:
  tokenizer_hidden_dim: 4096

  d_token: 784 # 6 + 3 + 3 + 4 + 768
  n_head: 8
  n_layer: 8
  d_model: 1024
  decoder_dropout: 0.1
  dim_gru_single_emb: 128

  position_embedding_dropout: 0.1

  ffd_hidden_dim: 4096
  ffd_dropout: 0.2

  encoder_kv_dim: 1024 # decided by pretrained model.

## Module Parameter Config.
## It will read from above parameter.
## No need to change here.
tokenizer:
  type: MLPTokenizerV2
  args:
    d_token: model_parameter.d_token
    d_hidden: model_parameter.tokenizer_hidden_dim
    d_model: model_parameter.d_model
    drop_out: model_parameter.decoder_dropout

untokenizer:
  type: MLPUnTokenizerV2
  args:
    d_token: model_parameter.d_token
    d_hidden: model_parameter.tokenizer_hidden_dim
    d_model: model_parameter.d_model
    drop_out: model_parameter.decoder_dropout

position_embedding:
  type: PositionGRUEmbedding
  args:
    d_model: model_parameter.d_model
    dim_single_emb: model_parameter.dim_gru_single_emb
    dropout: model_parameter.position_embedding_dropout

decoder:
  type: DecoderV2
  args:
    config: '.'
    n_layer: model_parameter.n_layer
    device: device
  layer_arges:
    n_head: model_parameter.n_head
    d_model: model_parameter.d_model
    dropout: model_parameter.decoder_dropout
    encoder_kv_dim: model_parameter.encoder_kv_dim

feedforward: # TODO: try KAN.
  args:
    d_model: model_parameter.d_model
    hidden_dim: model_parameter.ffd_hidden_dim
    dropout: model_parameter.ffd_dropout


