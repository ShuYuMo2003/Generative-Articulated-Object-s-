usewandb: true
random_seed: love ytq forever.
device: null

action:
  type: train
  args:
    n_epoch: 1000000
    ckpt_save_path: checkpoints/transformer-text
    per_epoch_save: 10
    betas: [0.9, 0.98]
    eps: 1e-9
    scheduler_factor: 0.0025
    scheduler_warmup: 30
    # n_validation_sample: 12 # Change this by change `evaluate_dataset.cut_off`
    latent_code_loss_ratio: 0.8
    vq_loss_ratio: 0.1
    sample_image_freq: 10

evaluator:
  gensdf_model_path: null
  eval_mesh_output_path: logs/transformer_eval_mesh_output_path
  resolution: 16
  max_batch: 262144 # 2 ^ 18

# Dataset & Dataloader config
dataset:
  type: file
  args:
    dataset_path: dataset/4_transformer_dataset
    description_for_each_file: 6
    cut_off: -1 # 参与评估的数据量
    enc_data_fieldname: description

evaluate_dataset:
  type: file
  args:
    dataset_path: dataset/4_transformer_dataset
    description_for_each_file: 6
    cut_off: 256 # 参与评估的数据量
    enc_data_fieldname: description

dataloader:
  args:
    batch_size: 256
    num_workers: 20
    shuffle: true
    pin_memory: true
    persistent_workers: true
    drop_last: true

evaluate_dataloader:
  args:
    batch_size: 256
    num_workers: 22
    shuffle: false

part_structure:
  bounding_box: 6
  joint_data_origin: 3
  joint_data_direction: 3
  limit: 4
  latent_code: 256

# Global Model Parameters
model_parameter:
  tokenizer_hidden_dim: 2048

  d_token: 272 # 6 + 3 + 3 + 4 + 256
  n_head: 8
  n_layer: 8
  d_model: 1024
  decoder_dropout: 0.1
  dim_gru_single_emb: 256

  position_embedding_dropout: 0.1

  ffd_hidden_dim: 4096
  ffd_dropout: 0.3

  encoder_kv_dim: 1024 # decided by pretrained encoder model.
  post_encoder_deepth: 3

  vectorQuantizer:
    n_e: 512
    e_dim: 128
    n_channel: 128
    temperature: 0.5
    beta: 0.25

## Module Parameter Config.
## It will read from above parameter.
## No need to change here.

tokenizer:
  type: MLPTokenizerV2
  args:
    d_token: model_parameter.d_token
    d_hidden: model_parameter.tokenizer_hidden_dim
    d_model: model_parameter.d_model
    drop_out: model_parameter.decoder_dropout

untokenizer:
  type: MLPUnTokenizerV2
  args:
    d_token: model_parameter.d_token
    d_hidden: model_parameter.tokenizer_hidden_dim
    d_model: model_parameter.d_model
    drop_out: model_parameter.decoder_dropout

position_embedding:
  type: PositionGRUEmbedding
  args:
    d_model: model_parameter.d_model
    dim_single_emb: model_parameter.dim_gru_single_emb
    dropout: model_parameter.position_embedding_dropout

decoder:
  type: DecoderV2
  args:
    config: '.'
    n_layer: model_parameter.n_layer
    device: device
  layer_arges:
    n_head: model_parameter.n_head
    d_model: model_parameter.d_model
    dropout: model_parameter.decoder_dropout
    encoder_kv_dim: model_parameter.encoder_kv_dim

feedforward: # TODO: try KAN.
  args:
    d_model: model_parameter.d_model
    hidden_dim: model_parameter.ffd_hidden_dim
    dropout: model_parameter.ffd_dropout


