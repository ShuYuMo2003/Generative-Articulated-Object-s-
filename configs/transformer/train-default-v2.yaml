usewandb: true
random_seed: love ytq forever
device: null

action:
  type: train
  args:
    n_epoch: 1000000
    ckpt_save_name: checkpoints/transformer/native-{epoch:05d}.ckpt
    per_epoch_save: 300
    betas: [0.9, 0.98]
    eps: 1e-9
    scheduler_factor: 0.01
    scheduler_warmup: 100
    evaluetaion: true
    n_validation_sample: 10
    main_loss_ratio: 1
    train_with_decoder: false

######### For evaluation ONLY, the paramerters for latentcode decoder.
n_latent_code_validation_samples: 10000
latent_decoder:
  type: null
  ckpt_path:
######### END

# Dataset & Dataloader config
dataset:
  type: redis_parallel
  args:
    db: 0
    port: 6379
    host: localhost
    fix_length: 5

dataloader:
  args:
    batch_size: 8
    num_workers: 2
    shuffle: true

part_structure:
  non_latent_info:
    origin: 3
    direction: 3
    bounds: 6
    tran: 3
    limit: 4
  latent_info:
    latent: 128
  other_info:
    dec_samplepoint: [50000, 3]
    dec_occ: 50000

# Global Model Parameters
model_parameter:
  tokenizer_hidden_dim: 512
  tokenizer_leaky_relu: 0.1

  n_head: 16
  n_layer: 12
  d_model: 512
  max_part_len_embedding: 128
  decoder_dropout: 0.1
  expanded_d_model: 4096

  ffd_hidden_dim: 4096
  ffd_dropout: 0.1

## Module Parameter Config.
## It will read from above parameter.
## No need to change here.
tokenizer:
  type: NativeMLPTokenizer
  args:
    input_structure: part_structure
    d_model: model_parameter.d_model
    hidden_dim: model_parameter.tokenizer_hidden_dim
    latent_code_dim: part_structure.latent_info.latent
    leaky_relu: model_parameter.tokenizer_leaky_relu
    drop_out: model_parameter.decoder_dropout

position_embedding:
  type: NativeCatPositionEmbedding
  args:
    d_model: model_parameter.d_model
    max_len: model_parameter.max_part_len_embedding
    device: device

g_embedding:
  type: NativeGEmbedding
  args:
    vocab_size: part_structure.vocab_size
    d_model: model_parameter.d_model

untokenizer:
  type: NativeMLPUnTokenizer
  args:
    input_structure: part_structure
    d_model: model_parameter.d_model
    expanded_d_model: model_parameter.expanded_d_model
    latent_code_dim: part_structure.latent_info.latent
    dropout: model_parameter.decoder_dropout

decoder:
  type: ParallelDecoder
  args:
    config: '.'
    n_layer: model_parameter.n_layer
    device: device
  layer_arges:
    n_head: model_parameter.n_head
    d_model: model_parameter.d_model
    dropout: model_parameter.decoder_dropout

feedforward: # TODO: try KAN.
  args:
    d_model: model_parameter.d_model
    hidden_dim: model_parameter.ffd_hidden_dim
    dropout: model_parameter.ffd_dropout


